# July 17, 2021 - Interspecies Conversations Closed Door Workshop 

## hosted by Interspecies.IO

It was a tremendous honor to present a Lightning Talk to the [Interspecies.IO](https://interspecies.io/) community during their [annual 2020 Conference](https://www.interspecies.io/conferences/workshop-2020). The workshop was hosted by Interspecies.IO, a multidisciplinary group founded by Peter Gabriel (musician and activist), Dr. Vint Cerf (Vice President at Google and Co-designer of the Internet), Dr. Diana Reiss (Professor at Hunter College, a cognitive psychologist, and marine mammal scientist), and Dr. Neil Gershenfeld (head of MIT’s Center for Bits and Atoms).

## Attendees

The Interspecies.io annual conference brings together a multidisciplinary group of researchers in the fields of animal cognition and communication, neuroscience, anthropology, AI and computer sciences, philosophers, artists and musicians. Speakers present their current research and ideas about interspecies communication and approaches to deciphering the signals of non-human animals. The goal is to inspire and encourage new collaborative efforts and strengthen existing partnerships in these important areas of research. 

## Recording
[![video thumb](https://imgur.com/n1VFCH8.gif)](https://archive.org/details/interspecies-i-o-lightning-talks-439400617)

We were honored to present alongside many incredible scientists during the lightning talk portion of the conference, including Yossi Yovel, Klaus Zuberbühler, Stav Hertz, Jennifer Mather, Robert Remez, Laurance Doyle, and David Gruber. 
Earth Species Project co-founder Aza Raskin's Lightning Talk starts at 42:33. 

### Topics Covered
An introduction to the Earth Species Project's mission, team, [research roadmap](https://github.com/earthspecies/project), and the [Earth Species Project Library](https://github.com/earthspecies/library).  

## Referenced Earth Species Project Repositories 
 
- [Earth Species Library](https://github.com/earthspecies/library)

## Resources

#### Getting Started
- [Introduction to using Colab](https://colab.research.google.com/notebooks/intro.ipynb)
- [Digital Signal Processing with Python](https://github.com/earthspecies/intro-to-DSP-with-python)

#### Referenced Machine Learning Academic Publications 
- [A. Conneau, G. Lample, M. Ranzato, L. Denoyer: "Word Translation Without Parallel Data", 2017.](http://arxiv.org/abs/1710.04087) 
- [Artetxe, Mikel et al. “Unsupervised Neural Machine Translation.” ArXiv abs/1710.11041 (2018): n. pag.](http://arxiv.org/abs/1710.11041)
- [Beliy, Roman et al. “From voxels to pixels and back: Self-supervision in natural-image reconstruction from fMRI.” NeurIPS (2019).](https://arxiv.org/abs/1907.02431) 
- [Bell-Kligler, Sefi et al. “Blind Super-Resolution Kernel Estimation using an Internal-GAN.” NeurIPS (2019).](https://arxiv.org/abs/1909.06581)
- Benaim, Sagie et al. “SpeedNet: Learning the Speediness in Videos.” 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2020): 9919-9928. https://arxiv.org/pdf/2004.06130.pdf
- Bond-Taylor, Sam and Chris G. Willcocks. “Gradient Origin Networks.” ArXiv abs/2007.02798 (2020): n. pag. https://arxiv.org/abs/2007.02798
- Cer, Daniel Matthew et al. “Universal Sentence Encoder.” ArXiv abs/1803.11175 (2018): n. pag. http://arxiv.org/abs/1803.11175
- Chung, Yu-An et al. “Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces.” NeurIPS (2018). http://arxiv.org/abs/1805.07467
- Ethayarajh, Kawin et al. “Towards Understanding Linear Word Analogies.” ACL (2019). http://arxiv.org/abs/1810.04882
- Ethayarajh, Kawin. “How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings.” ArXiv abs/1909.00512 (2019): n. pag. https://www.aclweb.org/anthology/D19-1006.pdf
- Gandelsman, Yossi et al. ““Double-DIP”: Unsupervised Image Decomposition via Coupled Deep-Image-Priors.” 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2019): 11018-11027. https://arxiv.org/abs/1812.00467
- M. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee: "Deep contextualized word representations", 2018. http://arxiv.org/abs/1802.05365
- Sainburg T, Thielk M, Gentner TQ (2020) Finding, visualizing, and quantifying latent structure across diverse animal vocal repertoires. PLOS Computational Biology 16(10): e1008228. https://doi.org/10.1371/journal.pcbi.1008228
- Schuster, Tal et al. “Cross-Lingual Alignment of Contextual Word Embeddings, with Applications to Zero-shot Dependency Parsing.” NAACL-HLT (2019). http://arxiv.org/abs/1902.09492
- Shocher, Assaf et al. “"Zero-Shot" Super-Resolution Using Deep Internal Learning.” CVPR (2018). https://arxiv.org/pdf/1712.06087.pdf
- Shocher, Assaf et al. “From Discrete to Continuous Convolution Layers.” ArXiv abs/2006.11120 (2020): n. pag. https://arxiv.org/pdf/2006.11120.pdf
- Shocher, Assaf et al. “Internal Distribution Matching for Natural Image Retargeting.” ArXiv abs/1812.00231 (2018): n. pag. https://arxiv.org/abs/1812.00231
- Shocher, Assaf et al. “Semantic Pyramid for Image Generation.” 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2020): 7455-7464. https://arxiv.org/pdf/2003.06221.pdf
- Sitzmann, V. et al. “Implicit Neural Representations with Periodic Activation Functions.” ArXiv abs/2006.09661 (2020): n. pag. https://arxiv.org/abs/2006.09661
- T. Mikolov, K. Chen, G. Corrado: "Efficient Estimation of Word Representations in Vector Space", 2013. http://arxiv.org/abs/1301.3781
- Zuckerman, Liad Pollak et al. “Across Scales \& Across Dimensions: Temporal Super-Resolution using Deep Internal Learning.” ECCV (2020). https://arxiv.org/pdf/2007.02798.pdf
