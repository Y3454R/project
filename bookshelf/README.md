# Bookshelf / Resources

A collection of books, papers, and articles on our continental shelves 🌊📚

## Papers

### Machine Learning
- [A. Conneau, G. Lample, M. Ranzato, L. Denoyer: "Word Translation Without Parallel Data", 2017.](http://arxiv.org/abs/1710.04087) 
- [Artetxe, Mikel et al. “Unsupervised Neural Machine Translation.” ArXiv abs/1710.11041 (2018): n. pag.](http://arxiv.org/abs/1710.11041)
- [Beliy, Roman et al. “From voxels to pixels and back: Self-supervision in natural-image reconstruction from fMRI.” NeurIPS (2019).](https://arxiv.org/abs/1907.02431) 
- [Bell-Kligler, Sefi et al. “Blind Super-Resolution Kernel Estimation using an Internal-GAN.” NeurIPS (2019).](https://arxiv.org/abs/1909.06581)
- Benaim, Sagie et al. “SpeedNet: Learning the Speediness in Videos.” 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2020): 9919-9928. https://arxiv.org/pdf/2004.06130.pdf
- Bermant, P.C., Bronstein, M.M., Wood, R.J. et al. Deep Machine Learning Techniques for the Detection and Classification of Sperm Whale Bioacoustics. Sci Rep 9, 12588 (2019).(https://www.nature.com/articles/s41598-019-48909-4)
- Bond-Taylor, Sam and Chris G. Willcocks. “Gradient Origin Networks.” ArXiv abs/2007.02798 (2020): n. pag. https://arxiv.org/abs/2007.02798
- Cer, Daniel Matthew et al. “Universal Sentence Encoder.” ArXiv abs/1803.11175 (2018): n. pag. http://arxiv.org/abs/1803.11175
- Chung, Yu-An et al. “Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces.” NeurIPS (2018). http://arxiv.org/abs/1805.07467
- Ethayarajh, Kawin et al. “Towards Understanding Linear Word Analogies.” ACL (2019). http://arxiv.org/abs/1810.04882
- Ethayarajh, Kawin. “How Contextual are Contextualized Word Representations? Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings.” ArXiv abs/1909.00512 (2019): n. pag. https://www.aclweb.org/anthology/D19-1006.pdf
- Gandelsman, Yossi et al. ““Double-DIP”: Unsupervised Image Decomposition via Coupled Deep-Image-Priors.” 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2019): 11018-11027. https://arxiv.org/abs/1812.00467
- M. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee: "Deep contextualized word representations", 2018. http://arxiv.org/abs/1802.05365
- Sainburg T, Thielk M, Gentner TQ (2020) Finding, visualizing, and quantifying latent structure across diverse animal vocal repertoires. PLOS Computational Biology 16(10): e1008228. https://doi.org/10.1371/journal.pcbi.1008228
- Schuster, Tal et al. “Cross-Lingual Alignment of Contextual Word Embeddings, with Applications to Zero-shot Dependency Parsing.” NAACL-HLT (2019). http://arxiv.org/abs/1902.09492
- Shocher, Assaf et al. “"Zero-Shot" Super-Resolution Using Deep Internal Learning.” CVPR (2018). https://arxiv.org/pdf/1712.06087.pdf
- Shocher, Assaf et al. “From Discrete to Continuous Convolution Layers.” ArXiv abs/2006.11120 (2020): n. pag. https://arxiv.org/pdf/2006.11120.pdf
- Shocher, Assaf et al. “Internal Distribution Matching for Natural Image Retargeting.” ArXiv abs/1812.00231 (2018): n. pag. https://arxiv.org/abs/1812.00231
- Shocher, Assaf et al. “Semantic Pyramid for Image Generation.” 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2020): 7455-7464. https://arxiv.org/pdf/2003.06221.pdf
- Sitzmann, V. et al. “Implicit Neural Representations with Periodic Activation Functions.” ArXiv abs/2006.09661 (2020): n. pag. https://arxiv.org/abs/2006.09661
- T. Mikolov, K. Chen, G. Corrado: "Efficient Estimation of Word Representations in Vector Space", 2013. http://arxiv.org/abs/1301.3781
- Zuckerman, Liad Pollak et al. “Across Scales \& Across Dimensions: Temporal Super-Resolution using Deep Internal Learning.” ECCV (2020). https://arxiv.org/pdf/2007.02798.pdf

### DSP & Sound

- [T. Gardner, M. Magnasco: "Sparse time-frequency representations", 2006 PNAS](https://doi.org/10.1073/pnas.0601707103)
